{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Текстовые функции и вложения в CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Установите GPU в качестве аппаратного ускорителя**\n",
    "\n",
    "    Прежде всего, вам нужно выбрать GPU в качестве аппаратного ускорителя. Для этого есть два простых шага:\n",
    "    Шаг 1. Перейдите к **Runtime** меню и выберите пункт **Change runtime type**\n",
    "    Шаг 2. Выбирать **GPU** в качестве аппаратного ускорителя.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import catboost\n",
    "print(catboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = (df['toxic'] > 0).astype(int)\n",
    "df.drop(['toxic'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (127656, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, train_size=0.8, random_state=0)\n",
    "y_train, X_train = train_df['label'], train_df.drop(['label'], axis=1)\n",
    "y_test, X_test = test_df['label'], test_df.drop(['label'], axis=1)\n",
    "\n",
    "train_pool = Pool(data=X_train, label=y_train, text_features=['text'])\n",
    "test_pool = Pool(data=X_test, label=y_test, text_features=['text'])\n",
    "\n",
    "print('Train dataset shape: {}\\n'.format(train_pool.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6723927\ttest: 0.6973663\tbest: 0.6973663 (0)\ttotal: 74.4ms\tremaining: 1m 14s\n",
      "100:\tlearn: 0.6857495\ttest: 0.7003308\tbest: 0.7005748 (98)\ttotal: 7.71s\tremaining: 1m 8s\n",
      "200:\tlearn: 0.6988857\ttest: 0.7042352\tbest: 0.7049381 (149)\ttotal: 14.8s\tremaining: 58.8s\n",
      "300:\tlearn: 0.7088843\ttest: 0.7066036\tbest: 0.7079398 (269)\ttotal: 21.8s\tremaining: 50.7s\n",
      "400:\tlearn: 0.7144059\ttest: 0.7060266\tbest: 0.7079398 (269)\ttotal: 28.5s\tremaining: 42.6s\n",
      "500:\tlearn: 0.7206808\ttest: 0.7059444\tbest: 0.7079398 (269)\ttotal: 35.5s\tremaining: 35.4s\n",
      "600:\tlearn: 0.7257021\ttest: 0.7060271\tbest: 0.7084651 (522)\ttotal: 42.3s\tremaining: 28.1s\n",
      "700:\tlearn: 0.7302824\ttest: 0.7063785\tbest: 0.7084651 (522)\ttotal: 49.2s\tremaining: 21s\n",
      "800:\tlearn: 0.7338792\ttest: 0.7063994\tbest: 0.7084651 (522)\ttotal: 56.2s\tremaining: 14s\n",
      "900:\tlearn: 0.7387252\ttest: 0.7082163\tbest: 0.7090207 (878)\ttotal: 1m 3s\tremaining: 6.92s\n",
      "999:\tlearn: 0.7426678\ttest: 0.7080702\tbest: 0.7094962 (945)\ttotal: 1m 9s\tremaining: 0us\n",
      "bestTest = 0.7094962261\n",
      "bestIteration = 945\n",
      "Shrink model to first 946 iterations.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "def fit_model(train_pool, test_pool, **kwargs):\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.1,\n",
    "        eval_metric='F1',\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return model.fit(\n",
    "        train_pool,\n",
    "        eval_set=test_pool,\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "model = fit_model(train_pool, test_pool, task_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как это работает\n",
    "\n",
    "    1. Токенизация Текста\n",
    "    2. Создание Словаря\n",
    "    3. Расчет Характеристик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация Текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно мы получаем наш текст в виде последовательности символов Юникода. Таким образом, если задача не является классификацией ДНК, нам не нужна такая детализация, более того, нам нужно извлечь более сложные сущности, например слова. Процесс извлечения токенов-слов, цифр, знаков препинания или специальных символов, которые определяют эмодзи из последовательности, называется **токенизацией**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация-это первая часть предварительной обработки текста в CatBoost и выполняется как простое разбиение последовательности на строковый шаблон (например, пробел)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_small = [\n",
    "    \"Cats are so cute :)\",\n",
    "    \"Mouse scare...\",\n",
    "    \"The cat defeated the mouse\",\n",
    "    \"Cute: Mice gather an army!\",\n",
    "    \"Army of mice defeated the cat :(\",\n",
    "    \"Cat offers peace\",\n",
    "    \"Cat is scared :(\",\n",
    "    \"Cat and mouse live in peace :)\"\n",
    "]\n",
    "\n",
    "target_small = [1, 0, 1, 1, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.text_processing import Tokenizer\n",
    "\n",
    "simple_tokenizer = Tokenizer()\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return [simple_tokenizer.tokenize(text) for text in texts]\n",
    "\n",
    "simple_tokenized_text = tokenize_texts(text_small)\n",
    "simple_tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная предварительная обработка\n",
    "\n",
    "Давайте подробнее рассмотрим результат токенизации небольшого текстового примера-токены содержат много ошибок:\n",
    "\n",
    "1. Они склеены пунктуацией 'Cute:', 'army!', 'skare...'.\n",
    "2. Слово 'Cat' and 'cat', 'Mice' и 'mice' кажется, они имеют одно и то же значение, Возможно, это должны быть одни и те же символы.\n",
    "3. Та же проблема и с токенами 'are'/'is' -- это флективные формы одного и того же знака 'be'.\n",
    "    \n",
    "    **Пунктуационная обработка** , **строчной**, и **лемматизация** процессы помогают преодолеть эти проблемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка знаков препинания и строчные буквы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    lowercasing=True,\n",
    "    separator_type='BySense',\n",
    "    token_types=['Word', 'Number']\n",
    ")\n",
    "\n",
    "tokenized_text = [tokenizer.tokenize(text) for text in text_small]\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Стоп - слова** -слова, которые считаются неинформативными в этой задаче, например функциональные слова, такие как, is, at, which, on. Обычно стоп-слова удаляются во время предварительной обработки текста, чтобы уменьшить объем информации, которая рассматривается для дальнейших алгоритмов. Стоп-слова собираются вручную (в виде словаря) или автоматически, например, беря наиболее частые слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(('be', 'is', 'are', 'the', 'an', 'of', 'and', 'in'))\n",
    "\n",
    "def filter_stop_words(tokens):\n",
    "    return list(filter(lambda x: x not in stop_words, tokens))\n",
    "    \n",
    "tokenized_text_no_stop = [filter_stop_words(tokens) for tokens in tokenized_text]\n",
    "tokenized_text_no_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемма (Википедия) - это каноническая форма, словарная форма или форма цитирования набора слов.\n",
    "Например, Лемма \"go\" представляет собой формы \"go\", \"goes\", \"going\", \"went\", and \"gone\". Процесс преобразования слова в его лемму называется **лемматизация**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk_data_path = os.path.join(os.path.dirname(nltk.__file__), 'nltk_data')\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "nltk.download('wordnet', nltk_data_path)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens_nltk(tokens):\n",
    "    return list(map(lambda t: lemmatizer.lemmatize(t), tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_small_lemmatized_nltk = [lemmatize_tokens_nltk(tokens) for tokens in tokenized_text_no_stop]\n",
    "text_small_lemmatized_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь слова с одинаковым значением представлены одним и тем же маркером, лексемы не склеиваются с пунктуацией.\n",
    "\n",
    "Будьте осторожны. Вы должны проверить это для своей собственной задачи:\n",
    "Действительно ли необходимо удалять знаки препинания, строчные предложения или выполнять лемматизацию и/или токенизацию слов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Давайте проверим точность с помощью новой предварительной обработки текста\n",
    "Поскольку CatBoost не выполняет интервальную пунктуацию, строчные буквы и лемматизацию, нам нужно предварительно обработать текст вручную, а затем передать его алгоритму обучения.\n",
    "\n",
    "Поскольку естественными текстовыми признаками являются только конспект и обзор, мы будем предварительно обрабатывать только их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def preprocess_data(X):\n",
    "    X_preprocessed = X.copy()\n",
    "    X_preprocessed['review'] = X['review'].apply(lambda x: ' '.join(lemmatize_tokens_nltk(tokenizer.tokenize(x))))\n",
    "    return X_preprocessed\n",
    "\n",
    "X_preprocessed_train = preprocess_data(X_train)\n",
    "X_preprocessed_test = preprocess_data(X_test)\n",
    "\n",
    "train_processed_pool = Pool(\n",
    "    X_preprocessed_train, y_train, \n",
    "    text_features=['review'],\n",
    ")\n",
    "\n",
    "test_processed_pool = Pool(\n",
    "    X_preprocessed_test, y_test, \n",
    "    text_features=['review'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_on_processed_data = fit_model(train_processed_pool, test_processed_pool, task_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score_diff(first_model, second_model):\n",
    "    first_accuracy = first_model.best_score_['validation']['AUC']\n",
    "    second_accuracy = second_model.best_score_['validation']['AUC']\n",
    "\n",
    "    gap = (second_accuracy - first_accuracy) / first_accuracy * 100\n",
    "\n",
    "    print('{} vs {} ({:+.2f}%)'.format(first_accuracy, second_accuracy, gap))\n",
    "    \n",
    "print_score_diff(model, model_on_processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание Словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После первого этапа, предварительной обработки текста и токенизации, начинается второй этап. Второй этап использует подготовленный текст для выбора набора единиц измерения, которые будут использоваться для построения новых числовых признаков.\n",
    "\n",
    "Набор выбранных единиц называется словарем. Он может содержать слова, биграммы слов или символьные n-граммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.text_processing import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_small_lemmatized_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(occurence_lower_bound=0, max_dictionary_size=10)\n",
    "\n",
    "dictionary.fit(text_small_lemmatized_nltk);\n",
    "#dictionary.fit(text_small, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('dictionary.tsv')\n",
    "!cat dictionary.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.apply([text_small_lemmatized_nltk[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчет Характеристик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование в векторы фиксированного размера\n",
    "\n",
    "Большинство классических алгоритмов ML вычисляют и выполняют предсказания на фиксированном числе объектов $F$.<br>\n",
    "Это означает, что набор обучения $X= (x_i) $ содержит векторы $x_i = (a_0, a_1, ..., a_F)$ где  $F$ константа.    \n",
    "\n",
    "Так как текстовый объект $x$ это не вектор фиксированной длины, нам нужно выполнить предварительную обработку исходного набора $D$.<br>\n",
    "Одним из самых простых методов кодирования текста в вектор является **Мешок слов (BoW)**.\n",
    "\n",
    "### Алгоритм мешка слов\n",
    "\n",
    "Алгоритм принимает в себя словарь и текст.<br>\n",
    "Во время работы алгоритма текст $x = (a_0, a_1, ..., a_k)$ преобразовано в вектор $\\\\tilde x = (b_0, b_1, ..., b_F)$,<br> где  $b_i$ это 0/1 (в зависимости от того, есть ли слово с id=$i$ из словаря в текст $x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc_train_small, y_train_small = X_preprocessed_train[:1000]['review'].to_list(), y_train[:1000]\n",
    "X_proc_train_small = list(map(simple_tokenizer.tokenize, X_proc_train_small))\n",
    "X_proc_test_small, y_test_small = X_preprocessed_test[:1000]['review'].to_list(), y_test[:1000]\n",
    "X_proc_test_small = list(map(simple_tokenizer.tokenize, X_proc_test_small))\n",
    "\n",
    "dictionary = Dictionary(max_dictionary_size=100)\n",
    "dictionary.fit(X_proc_train_small);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_text, dictionary):\n",
    "    features = np.zeros((len(tokenized_text), dictionary.size))\n",
    "    for i, tokenized_sentence in enumerate(tokenized_text):\n",
    "        indices = np.array(dictionary.apply([tokenized_sentence])[0])\n",
    "        if len(indices) > 0:\n",
    "            features[i, indices] = 1\n",
    "    return features\n",
    "\n",
    "X_bow_train_small = bag_of_words(X_proc_train_small, dictionary)\n",
    "X_bow_test_small = bag_of_words(X_proc_test_small, dictionary)\n",
    "X_bow_train_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fit_linear_model(X, y):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def evaluate_model_auc(model, X, y):\n",
    "    y_pred = model.predict_proba(X)[:,1]\n",
    "    metric = roc_auc_score(y, y_pred)\n",
    "    print('AUC: ' + str(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    linear_model = fit_linear_model(X_train, y_train)\n",
    "        \n",
    "    print('Linear model')\n",
    "    evaluate_model_auc(linear_model, X_test, y_test)\n",
    "    print('Comparing to constant prediction')\n",
    "    auc_constant_prediction = roc_auc_score(y_test, np.ones(shape=(len(y_test), 1)) * 0.5)\n",
    "    print('AUC: ' + str(auc_constant_prediction))\n",
    "    \n",
    "evaluate_models(X_bow_train_small, y_train_small, X_bow_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_dictionary = Dictionary(occurence_lower_bound=0, max_dictionary_size=1000)\n",
    "unigram_dictionary.fit(X_proc_train_small)\n",
    "\n",
    "X_bow_train_small = bag_of_words(X_proc_train_small, unigram_dictionary)\n",
    "X_bow_test_small = bag_of_words(X_proc_test_small, unigram_dictionary)\n",
    "print(X_bow_train_small.shape)\n",
    "\n",
    "evaluate_models(X_bow_train_small, y_train_small, X_bow_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глядя на последовательности букв / слов\n",
    "\n",
    "Давайте рассмотрим пример: тексты \"кошка победила мышь\" и \" армия мышей победила кошку:('<br>\n",
    "Упрощая его, мы имеем три лексемы в каждом предложении \"кошка побеждает мышь\" и \"мышь побеждает кошку'.<br>\n",
    "После применения лука мы получаем два равных вектора с противоположным значением:\n",
    "\n",
    "| cat | mouse | defeat |\n",
    "|-----|-------|--------|\n",
    "| 1   | 1     | 1      |\n",
    "| 1   | 1     | 1      |\n",
    "\n",
    "Как их отличить?\n",
    "Давайте добавим последовательности слов в виде отдельных лексем в наш словарь:\n",
    "\n",
    "| cat | mouse | defeat | cat_defeat | mouse_defeat | defeat_cat | defeat_mouse |\n",
    "|-----|-------|--------|------------|--------------|------------|--------------|\n",
    "| 1   | 1     | 1      | 1          | 0            | 0          | 1            |\n",
    "| 1   | 1     | 1      | 0          | 1            | 1          | 0            |\n",
    "\n",
    "**N-gram** это непрерывная последовательность $n$ элементов из заданного образца текста или речи (Wikipedia).<br>\n",
    "В приведенном выше примере Bi-gram (Bigram)  = 2 слова\n",
    "\n",
    "Nграммы помогают добавить в векторы больше информации о структуре текста, более того, существуют n-граммы, не имеющие значения в разделении, например, 'Mickey Mouse company'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(occurence_lower_bound=0, gram_order=2)\n",
    "dictionary.fit(text_small_lemmatized_nltk)\n",
    "\n",
    "dictionary.save('dictionary.tsv')\n",
    "!cat dictionary.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_dictionary = Dictionary(occurence_lower_bound=0, max_dictionary_size=5000, gram_order=2)\n",
    "bigram_dictionary.fit(X_proc_train_small)\n",
    "\n",
    "X_bow_train_small = bag_of_words(X_proc_train_small, bigram_dictionary)\n",
    "X_bow_test_small = bag_of_words(X_proc_test_small, bigram_dictionary)\n",
    "print(X_bow_train_small.shape)\n",
    "\n",
    "evaluate_models(X_bow_train_small, y_train_small, X_bow_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_train_small = np.concatenate((\n",
    "    bag_of_words(X_proc_train_small, unigram_dictionary),\n",
    "    bag_of_words(X_proc_train_small, bigram_dictionary)\n",
    "), axis=1)\n",
    "X_bow_test_small = np.concatenate((\n",
    "    bag_of_words(X_proc_test_small, unigram_dictionary),\n",
    "    bag_of_words(X_proc_test_small, bigram_dictionary)\n",
    "), axis=1)\n",
    "print(X_bow_train_small.shape)\n",
    "\n",
    "evaluate_models(X_bow_train_small, y_train_small, X_bow_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имя параметра:\n",
    "\n",
    "1. **Text Tokenization** - `tokenizers`\n",
    "2. **Dictionary Creation** - `dictionaries`\n",
    "3. **Feature Calculation** - `feature_calcers`\n",
    "\n",
    "\\* Более сложная конфигурация с `text_processing` параметр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tokenizers`\n",
    "\n",
    "Tokenizers used to preprocess Text type feature columns before creating the dictionary.\n",
    "\n",
    "[Documentation](https://catboost.ai/docs/references/tokenizer_options.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = [{\n",
    "    'tokenizerId': 'Space',\n",
    "    'delimiter': ' ',\n",
    "    'separator_type': 'ByDelimiter',\n",
    "},{\n",
    "    'tokenizerId': 'Sense',\n",
    "    'separator_type': 'BySense',\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dictionaries`\n",
    "\n",
    "Dictionaries used to preprocess Text type feature columns.\n",
    "\n",
    "[Documentation](https://catboost.ai/docs/references/dictionaries_options.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = [{\n",
    "    'dictionaryId': 'Unigram',\n",
    "    'max_dictionary_size': '50000',\n",
    "    'gram_count': '1',\n",
    "},{\n",
    "    'dictionaryId': 'Bigram',\n",
    "    'max_dictionary_size': '50000',\n",
    "    'gram_count': '2',\n",
    "},{\n",
    "    'dictionaryId': 'Trigram',\n",
    "    'token_level_type': 'Letter',\n",
    "    'max_dictionary_size': '50000',\n",
    "    'gram_count': '3',\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `feature_calcers`\n",
    "\n",
    "Калькуляторы объектов используются для расчета новых объектов на основе предварительно обработанных столбцов объектов текстового типа.\n",
    "\n",
    "1. **`BoW`**<br>\n",
    "Мешок слов: 0/1 features (образец текста имеет или не имеет token_id).<br>\n",
    "Количество произведенных числовые характеристики = размер словаря.<br>\n",
    "параметр: `top_tokens_count` - максимальное количество токенов, которые будут использоваться для векторизации в мешке слов, наиболее частые $n$ жетоны принимаются (**сильно влияет как на использование CPU ang GPU RAM**).\n",
    "\n",
    "2. **`NaiveBayes`**<br>\n",
    "NaiveBayes: [Полиномиальное упрощенного алгоритма Байеса](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes) модель. Добавлено столько же новых функций, сколько и классов. Эта функция вычисляется по аналогии со счетчиками в CatBoost путем перестановки ([оценка и показатели CTR](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html)). Другими словами, производится случайная перестановка, а затем мы идем сверху вниз по набору данных и вычисляем вероятность его принадлежности к этому классу для каждого объекта.\n",
    "\n",
    "3. **`BM25`**<br>\n",
    "[BM25](https://en.wikipedia.org/wiki/Okapi_BM25). Добавлено столько же новых функций, сколько и классов. Идея та же, что и в наивном Байесе, но для каждого класса мы вычисляем не условную вероятность, а определенную релевантность, что аналогично tf-idf, где лексемы вместо слов и классы вместо документов (точнее, объединение всех текстов этого класса). Только множитель tf в BM25 заменяется другим множителем, что дает преимущество классам, содержащим редкие токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_calcers = [\n",
    "    'BoW:top_tokens_count=1000',\n",
    "    'NaiveBayes',\n",
    "    'BM25',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `text_processing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processing = {\n",
    "    \"tokenizers\" : [{\n",
    "        \"tokenizer_id\" : \"Space\",\n",
    "        \"separator_type\" : \"ByDelimiter\",\n",
    "        \"delimiter\" : \" \"\n",
    "    }],\n",
    "\n",
    "    \"dictionaries\" : [{\n",
    "        \"dictionary_id\" : \"BiGram\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"2\"\n",
    "    }, {\n",
    "        \"dictionary_id\" : \"Word\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"1\"\n",
    "    }],\n",
    "\n",
    "    \"feature_processing\" : {\n",
    "        \"default\" : [{\n",
    "            \"dictionaries_names\" : [\"BiGram\", \"Word\"],\n",
    "            \"feature_calcers\" : [\"BoW\"],\n",
    "            \"tokenizers_names\" : [\"Space\"]\n",
    "        }, {\n",
    "            \"dictionaries_names\" : [\"Word\"],\n",
    "            \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "            \"tokenizers_names\" : [\"Space\"]\n",
    "        }],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Резюме: текстовые функции в CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм:\n",
    "1. Входной текст загружается в виде обычного столбца. ``text_column: [string]``.\n",
    "2. Каждый образец текста маркируется с помощью разбиения на пробелы. ``tokenized_column: [[string]]``.\n",
    "3. Оценка словаря.\n",
    "4. Каждая строка в маркированном столбце преобразуется в token_id из словаря. ``text: [[token_id]]``.\n",
    "5. В зависимости от параметров CatBoost производит функции на основе результирующего текстового столбца: Bag of words, Multinomial naive bayes или Bm25.\n",
    "6. Вычисленные объекты float передаются в обычный алгоритм обучения CatBoost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings In CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получить Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "big_model = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')\n",
    "X_embed_train = big_model.encode(X_train['review'].to_list())\n",
    "X_embed_test = big_model.encode(X_test['review'].to_list())\n",
    "\n",
    "#!wget https://transfersh.com/HDHxy/embedded_train.npy -O embedded_train.npy\n",
    "#X_embed_train = np.load('embedded_train.npy')\n",
    "\n",
    "#!wget https://transfersh.com/whOm3/embedded_test.npy -O embedded_test.npy\n",
    "#X_embed_test = np.load('embedded_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embed_first_train_small, y_first_train_small = X_embed_train[:5000], y_train[:5000]\n",
    "X_embed_second_train_small, y_second_train_small = X_embed_train[5000:10000], y_train[5000:10000]\n",
    "X_embed_test_small, y_test_small = X_embed_test[:5000], y_test[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чистые embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(X_embed_second_train_small, y_second_train_small, X_embed_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### линейный дискриминантный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "lda.fit(X_embed_first_train_small, y_first_train_small)\n",
    "\n",
    "X_lda_train_small = lda.transform(X_embed_second_train_small)\n",
    "X_lda_test_small = lda.transform(X_embed_test_small)\n",
    "print(X_lda_train_small.shape)\n",
    "evaluate_models(X_lda_train_small, y_second_train_small, X_lda_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings in CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('train_embed_text.tsv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t', quotechar='\"')\n",
    "    for y, text, row in zip(y_train, X_preprocessed_train['review'].to_list(), X_embed_train):\n",
    "        writer.writerow((str(y), text, ';'.join(map(str, row))))\n",
    "\n",
    "with open('test_embed_text.tsv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t', quotechar='\"')\n",
    "    for y, text, row in zip(y_test, X_preprocessed_test['review'].to_list(), X_embed_test):\n",
    "        writer.writerow((str(y), text, ';'.join(map(str, row))))\n",
    "        \n",
    "with open('pool_text.cd', 'w') as f:\n",
    "    f.write(\n",
    "        '0\\tLabel\\n'\\\n",
    "        '1\\tText\\n'\\\n",
    "        '2\\tNumVector'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "train_embed_pool = Pool('train_embed_text.tsv', column_description='pool_text.cd')\n",
    "test_embed_pool = Pool('test_embed_text.tsv', column_description='pool_text.cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text_embeddings = fit_model(train_embed_pool, test_embed_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score_diff(model, model_text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
