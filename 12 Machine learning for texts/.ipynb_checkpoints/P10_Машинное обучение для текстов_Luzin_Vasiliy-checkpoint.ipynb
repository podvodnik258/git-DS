{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, Василий! \n",
    "\n",
    "Меня зовут Светлана Медведева и я буду проверять Твою работу. Предлагаю общаться на \"ты\". \n",
    "\n",
    "Просьба при доработке работы оставлять мои комментарии без изменений.\n",
    "\n",
    "Комментарии я разделяю на следующие категории:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "В случае если всё верно!\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "В случае если можно что-то доработать, но эта доработка не критична или если есть варианты улучшения работы.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "Замечания, которые нужно исправить. Без исправления этих замечаний проект принят не может быть.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Резензия на работу v. 1</font>\n",
    "* К сожалению, я не могу запустить на сервере Твою работу. Проект падает с ошибкой \"The kernel appears to have died. It will restart automatically.\". Предлагаю попробовать вместо TfidfVectorizer другой метод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Резензия на работу v. 2</font>\n",
    "* Исправь, пожалуйста, ошибку в коде и я смогу продолжить проверку Твоего проекта :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Резензия на работу v. 3</font>\n",
    "* Работа засчитана :)\n",
    "* Успехов на следующем спринте!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 [Подготовка](#1)\n",
    "\n",
    "- [Просмотр данных](#1.1)\n",
    "- [Анализ данных](#1.1.1)\n",
    "- [Подготовка данных](#1.2.1)\n",
    "- [Предварительная обработка](#1.2)\n",
    "- [Токенизация. Обработка знаков препинания и строчных букв](#1.3)\n",
    "- [Удаление стоп-слов](#1.4)\n",
    "- [Лемматизация](#1.5)\n",
    "- [Создание корпусов текста](#1.6)\n",
    "- [Векторизация текста](#1.6.1)\n",
    "- [Регулярные выражения. Мешок слов и N-граммы](#1.6.2)\n",
    "- [TF-IDF для корпуса текстов](#1.7)\n",
    "- [Выбор метода векторизации](#1.7.1)\n",
    "\n",
    "2 [Обучение](#2)\n",
    "- [Метрика](#2.0.1)\n",
    "- [LogisticRegression](#2.1)\n",
    "- [RandomForestClassifier](#2.2)\n",
    "- [CatBoostClassifier](#2.2.1)\n",
    "- [BERT](#2.3)\n",
    "- [Выборка для BERT](#2.3.0)\n",
    "- [Загрузка предварительно обученной модели DistilBert](#2.3.1)\n",
    "- [Подготовка набора данных](#2.3.2)\n",
    "- [Тестирование DistilBert моделью LogisticRegression](#2.3.3)\n",
    "- [Проверка на адекватность](#2.3.4)\n",
    "\n",
    "3 [Выводы](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 1:\n",
    "    \n",
    "Молодец, что добавил оглавление со ссылками и кратко описал проект.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "import torch\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost.text_processing import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import transformers as trsfrs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка<a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Просмотр данных<a id=\"1.1\"></a>\n",
    "Загружаем данные, смотрим особенности датасета функцией `preview`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_tweets = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df_tweets = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Info ==========\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== missing data ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>text</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total  Percent\n",
       "toxic      0      0.0\n",
       "text       0      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== duplicated ==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== describe ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>toxic</td>\n",
       "      <td>159571.0</td>\n",
       "      <td>0.101679</td>\n",
       "      <td>0.302226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "toxic  159571.0  0.101679  0.302226  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== inspection ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def missing_data(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "def preview(data):\n",
    "    print('=='*5, 'Info' , '=='*5)\n",
    "    display(data.info())\n",
    "    print('=='*5, 'missing data', '=='*5)\n",
    "    display(missing_data(data))\n",
    "    print('=='*5, 'duplicated', '=='*5)\n",
    "    display(data.duplicated().sum())\n",
    "    print('=='*5, 'describe', '=='*5)\n",
    "    display(data.describe().T)\n",
    "    print('=='*5, 'inspection', '=='*5)\n",
    "    display(data.head(10))\n",
    "\n",
    "preview(df_tweets)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Комментарий ревьюера v. 1:\n",
    "    \n",
    "Проведи, пожалуйста, исследовательский анализ данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ответ: </b> Небольшой анализ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 2:\n",
    "    \n",
    "Отлично исследовательский анализ данных проведён.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных <a id=\"1.1.1\"></a>\n",
    "Изучим особенности целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_percent(data):\n",
    "    total = data.value_counts()\n",
    "    percent = (data.value_counts() / data.value_counts().sum()*100)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent']).head(5)\n",
    "\n",
    "def target_analize(target_column):\n",
    "    sns.countplot(target_column)\n",
    "    display(get_top_percent(target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>143346</td>\n",
       "      <td>89.832112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16225</td>\n",
       "      <td>10.167888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Total    Percent\n",
       "0  143346  89.832112\n",
       "1   16225  10.167888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_analize(df_tweets['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токсичных комментариев в датасете 10%. Датасет не сбалансирован."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 2:\n",
    "    \n",
    "Да, видно, что датасет не сбалансирован.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных<a id=\"1.2.1\"></a>\n",
    "Так, как имеется ограничения в памяти, то имеется возможность ограничить датасет, взяв только часть наблюдений.\n",
    "\n",
    "Создаем обучающие выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для стабильности раскомментировать\n",
    "df_tweets = df_tweets.sample(100000, random_state=42).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tweets\n",
    "y = df_tweets['toxic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (80000, 2) (80000,)\n",
      "test (20000, 2) (20000,)\n"
     ]
    }
   ],
   "source": [
    "print('train', X_train.shape, y_train.shape)\n",
    "print('test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 2:\n",
    "    \n",
    "Отлично, датасет разделён.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предварительная обработка<a id=\"1.2\"></a>\n",
    "Определляем Токенайзер, файл стоп-слов, проводим лемматизацию, создаём корпус твитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация. Обработка знаков препинания и строчных букв<a id=\"1.3\"></a>\n",
    " Процесс извлечения токенов-слов, цифр, знаков препинания или специальных символов, которые определяют эмодзи из последовательности, называется токенизацией.Выполняется как простое разбиение последовательности на строковый шаблон (например, пробел)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost.text_processing import Tokenizer\n",
    "tokenizer = Tokenizer(\n",
    "    lowercasing=True,\n",
    "    separator_type='BySense',\n",
    "    token_types=['Word'] # , 'Number'\n",
    ")\n",
    "\n",
    "# def tokenize_catboost(texts):\n",
    "#    return [tokenizer.tokenize(text) for text in texts]\n",
    "\n",
    "#tokenized_catboost = tokenize_catboost(corpus_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Удаление стоп-слов<a id=\"1.4\"></a>\n",
    "Стоп - слова -слова, которые считаются неинформативными в этой задаче, например функциональные слова, такие как, is, at, which, on. Обычно стоп-слова удаляются во время предварительной обработки текста, чтобы уменьшить объем информации, которая рассматривается для дальнейших алгоритмов. Стоп-слова собираются вручную (в виде словаря) или автоматически, например, беря наиболее частые слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#def filter_stop_words(tokens):\n",
    "#    return list(filter(lambda x: x not in stop_words, tokens))\n",
    "\n",
    "#def del_stop_words(tokenized_text):\n",
    "#    return [filter_stop_words(tokens) for tokens in tokenized_text]\n",
    "    \n",
    "#tokenized_text_no_stop = del_stop_words(tokenized_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация<a id=\"1.5\"></a>\n",
    "Лемма (Википедия) - это каноническая форма, словарная форма или форма цитирования набора слов. Например, Лемма \"go\" представляет собой формы \"go\", \"goes\", \"going\", \"went\", and \"gone\". Процесс преобразования слова в его лемму называется лемматизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens_nltk(tokens):\n",
    "    return list(map(lambda t: lemmatizer.lemmatize(t), tokens))\n",
    "\n",
    "#def lemmatize_apply(tokenized_no_stop):\n",
    "#    return [lemmatize_tokens_nltk(tokens) for tokens in tokenized_no_stop]\n",
    "#\n",
    "#text_lemmatized_nltk = lemmatize_apply(tokenized_text_no_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 2:\n",
    "    \n",
    "Дополнительные материалы по NLP: https://habr.com/ru/company/Voximplant/blog/446738/ \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание корпусов текста<a id=\"1.6\"></a>\n",
    "Чтобы алгоритмы умели определять тематику и тональность текста, их нужно обучить на корпусе (англ. corpus). Это набор текстов, в котором эмоции и ключевые слова уже размечены.\n",
    "Создадим корпус постов. Преобразуем столбец `text` в список текстов. Переведём тексты в стандартный для Python формат: кодировку `Unicode (U)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    X_preprocessed = X.copy()\n",
    "    X_preprocessed['text'] = X['text'].apply(lambda x: ' '.join(lemmatize_tokens_nltk(tokenizer.tokenize(x))))\n",
    "    return X_preprocessed\n",
    "\n",
    "corpus_train = preprocess_data(X_train)['text'].values.astype('U')\n",
    "corpus_test = preprocess_data(X_test)['text'].values.astype('U')\n",
    "\n",
    "print('corpus_train', corpus_train.shape)\n",
    "print('corpus_test', corpus_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Комментарий ревьюера v. 1:\n",
    "    \n",
    "Молодец, что используешь TfidfVectorizer, но попробуй, пожалуйста, убрать (закомментировать) этот метод из проекта, т. к. предположительно из-за него код падает на сервере с ошибкой (\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ответ: </b> В выборе метода можно поменять 1 на 0. А вообще мне кажется этот сервер от погоды зависит. То считает хорошо, то падает на загрузке данных. :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация текста<a id=\"1.6.1\"></a>\n",
    "Преобразование текста в векторы фиксированного размера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регулярные выражения. Мешок слов и N-граммы<a id=\"1.6.2\"></a>\n",
    "От лишних символов текст очистят регулярные выражения (англ. regular expressions). Это инструмент для поиска слова или числа по шаблону (англ. pattern). Он определяет, из каких частей состоит строка и какие в них символы. Например, нужно найти все даты в таком формате записи: 02.12.2020. Их шаблон — это два числа, точка, два числа, точка, четыре числа. Возьмём исходный текст твита. Под наш шаблон подходят английские символы и пробелы, которые как раз нужно оставить. Но если мы вызовем функцию re.sub(), их заменят пробелы. Чтобы указать, что символы под шаблон не подходят, перед набором символов поставим знак «домика» (^). Так в тексте остались только кириллические символы и пробелы. После этой операции в тексте можно обнаружить лишние пробелы, для анализа они — помеха. Пробелы устраняются комбинацией функций join() и split().\n",
    "Возьмём пример текста с лишними пробелами: в середине, начале и конце строки. Методом split() преобразуем его в список. Если не указывать аргументы у split(), он делает разбиение по пробелам или группам пробелов:\n",
    "\n",
    "Модель «мешок слов» (англ. bag of words) преобразует текст в вектор, не учитывая порядок слов. Отсюда и название — «мешок».\n",
    "Когда текстов несколько, мешок слов преобразует их в матрицу. Её строки — это тексты, а столбцы — уникальные слова из всех текстов корпуса. Числа на пересечении строк и столбцов показывают, сколько раз в тексте встречается уникальное слово. В мешке слов учитывается каждое уникальное слово. Но порядок слов и связи между ними не учитываются.\n",
    "\n",
    "N-грамма — это последовательность из нескольких слов. N указывает на количество элементов и может быть любым. Например, если N равно 1, получаются слова, или униграммы (лат. unus, «один»). При N=2 выходят словосочетания из двух слов — биграммы (лат. bis, «дважды»). Если N=3, то это уже триграммы (лат. tres, **«три»), т. е. из трёх слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    substitute = re.sub(r'[^A-Za-z]', ' ', text)\n",
    "    substitute = substitute.split()\n",
    "    substitute = ' '.join(substitute)\n",
    "    return substitute\n",
    "\n",
    "def clear_text_apply(corpus):\n",
    "    return [clear_text(text) for text in corpus]\n",
    "\n",
    "# создание n-граммы n_gramm, для которой n=1\n",
    "def n_gramm(corpus_train, corpus_test):\n",
    "    count_vect = CountVectorizer(analyzer='word', ngram_range=(1, 1), stop_words=stop_words) \n",
    "    n_gramm_train = count_vect.fit_transform(clear_text_apply(corpus_train))\n",
    "    n_gramm_test = count_vect.transform(clear_text_apply(corpus_test))\n",
    "    \n",
    "    return n_gramm_train, n_gramm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF для корпуса текстов<a id=\"1.7\"></a>\n",
    "Оценка важности слова определяется величиной TF-IDF (от англ. term frequency, «частота терма, или слова»; inverse document frequency, «обратная частота документа, или текста»). То есть TF отвечает за количество упоминаний слова в отдельном тексте, а IDF отражает частоту его употребления во всём корпусе. Большая величина TF-IDF говорит об уникальности слова в тексте по отношению к корпусу. Чем чаще оно встречается в конкретном тексте и реже в остальных, тем выше значение TF-IDF\n",
    "\n",
    "- $TF$ термина $а$ = (Количество раз, когда термин $а$ встретился в тексте / количество всех слов в тексте)\n",
    "\n",
    "$$\n",
    "TF = t/n, \n",
    "$$\n",
    "\n",
    "где $t$ (от англ. term) — количество употребления слова, а $n$ — общее число слов в тексте.\n",
    "\n",
    "\n",
    "- $IDF$ термина $а$ = логарифм(Общее количество документов / Количество документов, в которых встречается термин $а$)\n",
    "\n",
    "$$\n",
    "IDF = log10(D/d),\n",
    "$$\n",
    "\n",
    "где $D$ общее число текстов в корпусе и $d$ - количество текстов, в которых это слово встречается.\n",
    "\n",
    "\n",
    "- $TF-IDF$ термина $а$ = ($TF$ термина $а$) * ($IDF$ термина $а$)\n",
    "\n",
    "$$\n",
    "TF-IDF = TF*IDF\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(corpus_train, corpus_test):\n",
    "    count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "    tf_idf_train = count_tf_idf.fit_transform(corpus_train)\n",
    "    tf_idf_test = count_tf_idf.transform(corpus_test)\n",
    "    \n",
    "    return  tf_idf_train, tf_idf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор метода векторизации<a id=\"1.7.1\"></a>\n",
    "Здесь можно выбрать какой метод векторизации нужно использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 0 если используется N-grams \n",
    "# 1 если используется TF-IDF\n",
    "\n",
    "TEXT_VECTORIZATION_MODEL = 1\n",
    "\n",
    "if TEXT_VECTORIZATION_MODEL == 0:\n",
    "    vector_train, vector_test = n_gramm(corpus_train, corpus_test)\n",
    "elif TEXT_VECTORIZATION_MODEL == 1:\n",
    "    vector_train, vector_test = tf_idf(corpus_train, corpus_test)\n",
    "\n",
    "    \n",
    "    \n",
    "print(\"Размер матрицы vector_train:\", vector_train.shape)\n",
    "print(\"Размер матрицы vector_test:\", vector_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 2:\n",
    "    \n",
    "Молодец, что реализовал два метода векторизации :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение<a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика<a id=\"2.0.1\"></a>\n",
    "создаем метрику для использования в поиске гиперпараметров GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функции для подбора параметров, и вывода результата. На вход принимает модель, словарь с подбираемыми гиперпараметрами, данные для обучения. Возвращает f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение моделей\n",
    "def f1_score_model(model, X = vector_train, y = y_train, X_test = vector_test, y_test = y_test):\n",
    "    model.fit(X, y)\n",
    "    predict = model.predict(X_test)\n",
    "\n",
    "    print('f1_score test:', f1_score(y_test, predict))\n",
    "    \n",
    "# GridSearch\n",
    "def searchCV(estimator, param_grid, X, y):\n",
    "    gs = GridSearchCV(estimator=estimator,\n",
    "                          param_grid=param_grid,\n",
    "                          cv= 3,\n",
    "                          verbose = 0, \n",
    "                          scoring = f1,\n",
    "                          n_jobs=-1)\n",
    "    gs.fit(X, y)\n",
    "    print('best scrores GridSearch: ', gs.best_score_)\n",
    "    print('best scrores: ', gs.best_params_)\n",
    "    \n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression<a id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator = LogisticRegression(random_state=12345, class_weight='balanced') #\n",
    "param_grid = {\n",
    "    'C': [1, 2.5, 3], \n",
    "    'max_iter':np.linspace(100, 200, 2)\n",
    "}\n",
    "\n",
    "f1_score_model(searchCV(estimator, param_grid, vector_train, y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее модели RandomForestClassifier, CatBoostClassifier, DistilBert были посчитаны. К сожалению используемая память, видимо, превышает лимиты, и результаты вычислений я оставил перед расчетами. Сами расчеты не выполняются, находятся в формате raw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier<a id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out:\n",
    "\n",
    "    best scrores:  {'max_depth': 40, 'n_estimators': 80}\n",
    "    f1_score test: 0.04934687953555878\n",
    "    CPU times: user 8min 28s, sys: 0 ns, total: 8min 28s\n",
    "    Wall time: 8min 29s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Комментарий ревьюера v. 2:\n",
    "    \n",
    "Можешь, пожалуйста, исправить ошибку?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ответ: </b> Дальше до  DummyClassifier код не должен был исполняться. На сервере яндекса выпадает ошибка. Локально и colab работает нормально. Запустил RandomForestClassifier. нормально отработал. Не понял, где ошибка.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 3:\n",
    "    \n",
    "Странно, сейчас и у меня отрабатывает.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator = RandomForestClassifier(random_state=12345)\n",
    "param_grid = {\n",
    "    'max_depth' : [30, 40],\n",
    "    'n_estimators' : [60, 80]   \n",
    "}\n",
    "\n",
    "f1_score_model(searchCV(estimator, param_grid, vector_train, y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier<a id=\"2.2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out:\n",
    "\n",
    "    0:\tlearn: 0.3681632\ttotal: 479ms\tremaining: 2m 23s\n",
    "    50:\tlearn: 0.4389736\ttotal: 20.9s\tremaining: 1m 41s\n",
    "    100:\tlearn: 0.4771386\ttotal: 41.5s\tremaining: 1m 21s\n",
    "    150:\tlearn: 0.4812016\ttotal: 1m 1s\tremaining: 1m\n",
    "    200:\tlearn: 0.4931908\ttotal: 1m 22s\tremaining: 40.6s\n",
    "    250:\tlearn: 0.5012718\ttotal: 1m 42s\tremaining: 20s\n",
    "    299:\tlearn: 0.5184919\ttotal: 2m 2s\tremaining: 0us\n",
    "    f1_score CatBoostClassifier: 0.5238265854532427"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "def predict_model(X_train, y_train, X_valid, **kwargs):\n",
    "    CatBoost = CatBoostClassifier(eval_metric='F1', iterations=300, learning_rate=0.01, od_type='Iter', **kwargs)\n",
    "    CatBoost.fit(X_train, y_train, verbose=50)\n",
    "    return CatBoost.predict(X_valid)\n",
    "\n",
    "predict = predict_model(vector_train, y_train, vector_test)\n",
    "#\n",
    "print('f1_score CatBoostClassifier:', f1_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT <a id=\"2.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out:\n",
    "\n",
    "    best scrores GridSearch:  0.7220043572984749\n",
    "    best scrores:  {'C': 8.0, 'max_iter': 100.0}\n",
    "    f1_score test: 0.7500000000000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Комментарий ревьюера v. 1:\n",
    "    \n",
    "Доделай, пожалуйста, проект.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ответ: </b>Выполняю\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 2:\n",
    "    \n",
    "Отлично, модели построены и проанализированы, но я бы добавила ещё пару метрик (Accuracy и AUC-ROC) и отформатировала вывод (https://pyformat.info/ ).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выборка для BERT<a id=\"2.3.0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не создавать эмбеддинги слишком долго, возьмем из выборки только 400 случайных элементов. Для корректного тестирования поделим их на обучающую и тестовую выборки в соотношении 50:50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tweets.sample(400, random_state=42).reset_index(drop=True)\n",
    "train_bert, test_bert = train_test_split(df,  test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка предварительно обученной модели DistilBert<a id=\"2.3.1\"></a>\n",
    "модель переменных DistilBert содержит предварительно обученную модель BERT, которая меньше, но намного быстрее и требует гораздо меньше памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (trsfrs.DistilBertModel, trsfrs.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## для BERT:\n",
    "#model_class, tokenizer_class, pretrained_weights = (trsfrs.BertModel, trsfrs.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Загрузка предварительно подготовленных model/tokenizer\n",
    "token = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка набора данных<a id=\"2.3.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#определяем размер батча для обработки BERT-ом кратно выборке\n",
    "BATCH_SIZE = 20  \n",
    "\n",
    "def bert(text):\n",
    "    # Tokenization/ Ограничим длинну твита в 512, по условию модели\n",
    "    tokenized = text.apply((lambda x: token.encode(x, add_special_tokens=True, max_length=512)))\n",
    "\n",
    "    # Padding\n",
    "    # вычисляем максимальное кол-во токенов в предложении\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "        \n",
    "    #добавляем 0 для строк, у которых длина меньше максимальной\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    np.array(padded).shape\n",
    "\n",
    "    # Masking\n",
    "    # создаем маску, чтобы выделить значимые токены\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    # attention_mask.shape\n",
    "\n",
    "    # BATCH_SIZE = 40  #определяем размер батча для обработки BERT-ом\n",
    "    embeddings = []\n",
    "    for i in notebook.tqdm(range(padded.shape[0] // BATCH_SIZE)):\n",
    "        batch = torch.LongTensor(padded[BATCH_SIZE*i:BATCH_SIZE*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[BATCH_SIZE*i:BATCH_SIZE*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        \n",
    "    #полученные эмбеддинги будут признаками для обучения модели\n",
    "    bert_features = np.concatenate(embeddings) \n",
    "    print('shape:', bert_features.shape)\n",
    "    return bert_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_bert_train = bert(train_bert['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_bert_test = bert(test_bert['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование  DistilBert моделью LogisticRegression<a id=\"2.3.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "param_grid = {\n",
    "    'C': np.linspace(1, 8, 4), \n",
    "    'max_iter':np.linspace(100, 200, 3)\n",
    "}\n",
    "\n",
    "f1_score_model(searchCV(estimator, param_grid, X_bert_train, train_bert['toxic']),X_bert_train, train_bert['toxic'], X_bert_test, test_bert['toxic']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка на адекватность<a id=\"2.3.4\"></a>\n",
    "Насколько хороша метроика, мы можем узнать сравнив с результатами фиктивного классификатора, который покажет среднее распределение в целевом признаке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DummyClassifier()\n",
    "param_grid = {}\n",
    "\n",
    "f1_score_model(searchCV(estimator, param_grid, vector_train, y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат модели LogisticRegression f1 > 75 лучше чем DummyClassifier f1 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 3:\n",
    "    \n",
    "Отлично, модель на адекватность проверена.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие результаты задачи бинарной классификации текста показала модель логистической регрессии. Также предобученная модель bert может дать результаты. Для этой модели имеется возможность дообучить последний слой на нашем корпусе для более лучших показателей. RandomForestClassifier и CatBoostClassifier в этой задаче были безуспешны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Комментарий ревьюера v. 1:\n",
    "    \n",
    "Пока не могу посмотреть результаты, не запускается код (\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ответ: </b> Я \"За кулисами\" пробовал различные методы, наименее требовательные к ресурсам здесь, но и тем не хватает. Также использовал up и downsampling при обучении, другие модели. Лучший результат на отложенной выборке f1 0.8414574101427869 на BertForSequenceClassification. Но в этой работе модель даже не может загрузиться из репозитория. В плане dead kernel может помочь прогон всего батчами (не реализовано) или уменьшение датасета. В разделе <a href=\"#1.2.1\">Подготовка данных </a> раскомментировать, при необходимости сторку на 100000 записей. Метрика еле влезает.\n",
    "\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Комментарий ревьюера v. 2:\n",
    "    \n",
    "Отлично, наилучшая модель определена.\n",
    "    \n",
    "Материалы для дополнительного чтения: https://www.linguamatics.com/guide-choosing-right-natural-language-processing-solution\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
